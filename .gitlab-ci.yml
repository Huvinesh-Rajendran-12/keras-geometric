stages:
  - setup # Added stage for common setup
  - test
  - lint
  - build # Added explicit build stage
  - publish # Combined deploy/publish

variables:
  # Define Python versions to test
  PYTHON_VERSIONS: "3.9 3.10 3.11 3.12" # Space-separated list
  # Default Keras version (can be overridden)
  KERAS_VERSION: "keras>=3.0"
  # Default backend versions (can be overridden)
  TF_VERSION: "tensorflow-macos>=2.17" # Use tensorflow if not on macOS ARM
  TORCH_VERSION: "torch torch-geometric torch-scatter" # Add torch-scatter
  JAX_VERSION: "jax[cpu]"
  # Cache directories
  UV_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/uv"
  PIP_CACHE_DIR: ${CI_PROJECT_DIR}/.cache/pip

cache:
  key: ${CI_COMMIT_REF_SLUG}-${CI_JOB_IMAGE} # Cache per branch/tag and image
  paths:
    - ${UV_CACHE_DIR}
    - ${PIP_CACHE_DIR}
    - .venv # Cache the virtual environment per job

# --- Stage for common setup ---
install_uv:
  stage: setup
  image: python:3.11 # Use a recent Python version for uv install
  script:
    - echo "Installing uv..."
    # Check if uv is already installed (e.g., in cached .venv/bin)
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    # Verify installation
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin # Adjust activation based on install location
    - uv --version
  # No cache needed here, just ensures uv exists for subsequent stages if not cached via .venv

# --- Test Job Template ---
.test_template:
  stage: test
  variables:
    # Default backend if not specified by job
    KERAS_BACKEND: "tensorflow" # Default to TF if not overridden
  before_script:
    # Install uv (might be cached)
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin
    - uv --version
    # Setup venv (might be cached)
    - uv venv .venv --seed
    - source .venv/bin/activate
    # Install Keras first
    - uv pip install $KERAS_VERSION
    # Install specific backend based on job variable
    - |
      if [ "$KERAS_BACKEND" = "tensorflow" ]; then
        echo "Installing TensorFlow backend..."
        uv pip install $TF_VERSION
      elif [ "$KERAS_BACKEND" = "torch" ]; then
        echo "Installing PyTorch backend..."
        uv pip install $TORCH_VERSION
      elif [ "$KERAS_BACKEND" = "jax" ]; then
        echo "Installing JAX backend..."
        uv pip install $JAX_VERSION
      else
        echo "Error: Unknown KERAS_BACKEND value: $KERAS_BACKEND"
        exit 1
      fi
    # Install test dependencies AND the package itself editable
    - echo "Installing project + test dependencies..."
    - uv pip install -e ".[test]" # Includes pytest, pyg etc.
  script:
    # Set backend explicitly for Keras
    - export KERAS_BACKEND=${KERAS_BACKEND}
    - echo "Using Keras backend: $KERAS_BACKEND"
    - python -c "import keras; print(keras.backend.backend())" # Verify backend
    - echo "Running tests..."
    # Use unittest discover as used previously
    - uv run python -m unittest discover -s tests -v
  artifacts:
    when: on_failure # Optional: save venv cache on failure for debugging
    paths:
      - ${UV_CACHE_DIR}
      - ${PIP_CACHE_DIR}
      - .venv

# --- Generate Test Jobs ---
# Use GitLab's parallel:matrix feature for cleaner generation
test:
  extends: .test_template
  parallel:
    matrix:
      - PYTHON_VERSION: ["3.9", "3.10", "3.11", "3.12"]
        KERAS_BACKEND: ["tensorflow", "torch", "jax"]
  image: python:${PYTHON_VERSION}
  # Exclude combinations if needed (e.g., JAX on older Python)
  rules:
    - if: $PYTHON_VERSION == "3.9" && $KERAS_BACKEND == "jax"
      when: never # Example: If JAX isn't supported well on 3.9
    - when: on_success # Default rule

# --- Linting Job ---
lint:
  stage: lint
  image: python:3.11 # Use a consistent Python version for linting
  before_script:
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin
    - uv --version
    - uv venv .venv --seed
    - source .venv/bin/activate
    # Install lint tools AND project dependencies needed for mypy
    - uv pip install flake8 mypy types-PyYAML # Add any other lint deps
    - uv pip install -e ".[dev]" # Install project + deps for mypy analysis
  script:
    - echo "Running flake8..."
    - uv run flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
    - echo "Running mypy..."
    - uv run mypy src/

# --- Dependency Scanning Job ---
dependency_scan:
  stage: lint
  image: python:3.11 # Use a consistent Python version for scanning
  before_script:
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin
    - uv --version
    - uv venv .venv --seed
    - source .venv/bin/activate
    # Install project and scanning tools
    - uv pip install -e ".[dev]" # Install project + deps
    - uv pip install pip-audit safety # Install scanning tools
  script:
    - echo "Running pip-audit to scan for vulnerabilities..."
    - uv run pip-audit
    - echo "Running safety check to scan for vulnerabilities..."
    - uv run safety check

# --- Generate Release Notes Job ---
generate_release_notes:
  stage: build
  image: python:3.11 # Use a consistent Python version
  before_script:
    # Ensure git is installed
    - apt-get update && apt-get install -y --no-install-recommends git || apk add --no-cache git || yum install -y git
  script:
    - echo "Generating release notes for tag: $CI_COMMIT_TAG"
    # Get the previous tag
    - PREVIOUS_TAG=$(git describe --tags --abbrev=0 HEAD^ 2>/dev/null || echo "")
    - |
      if [ -z "$PREVIOUS_TAG" ]; then
        # If no previous tag, get all commits
        echo "No previous tag found. Getting all commits."
        COMMITS=$(git log --pretty=format:"* %s (%h)" --no-merges)
      else
        # Get commits between previous tag and current tag
        echo "Previous tag: $PREVIOUS_TAG"
        COMMITS=$(git log --pretty=format:"* %s (%h)" --no-merges $PREVIOUS_TAG..HEAD)
      fi
    # Create release notes with version and date
    - RELEASE_NOTES="## $CI_COMMIT_TAG ($(date +"%Y-%m-%d"))\n\n$COMMITS"
    # Save release notes to a file
    - echo "$RELEASE_NOTES" > release_notes.md
    # Print the release notes for debugging
    - echo "Generated Release Notes:"
    - cat release_notes.md
  artifacts:
    paths:
      - release_notes.md
  rules:
    # Generate release notes only when a tag is pushed
    - if: $CI_COMMIT_TAG

# --- Build Job ---
build_package:
  stage: build
  image: python:3.11 # Use a consistent Python version for building
  needs: [generate_release_notes] # Depend on release notes generation
  before_script:
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin
    - uv --version
    - uv venv .venv --seed
    - source .venv/bin/activate
    # Install build dependencies + hatch-vcs
    - uv pip install build hatch-vcs
  script:
    - echo "Building package for tag: $CI_COMMIT_TAG"
    # Ensure git history/tags are available for hatch-vcs
    - apt-get update && apt-get install -y --no-install-recommends git || apk add --no-cache git || yum install -y git # Install git if not present
    - git fetch --tags --unshallow --quiet || echo "Git unshallow failed or not needed."
    - uv run python -m build
  artifacts:
    paths:
      - dist/ # Save built artifacts
      - release_notes.md # Include release notes from previous job
  rules:
    # Build only when a tag is pushed
    - if: $CI_COMMIT_TAG

# --- Publish Job ---
publish_to_pypi:
  stage: publish
  image: python:3.11 # Use a consistent Python version for publishing
  needs: ["build_package"] # Depend on the build job
  before_script:
    - if ! command -v uv &> /dev/null; then curl -LsSf https://astral.sh/uv/install.sh | sh; fi
    - source $HOME/.cargo/env || source $HOME/.local/bin/uv || export PATH=$PATH:$HOME/.local/bin
    - uv --version
    - uv venv .venv --seed
    - source .venv/bin/activate
    # Install twine
    - uv pip install twine
  script:
    - echo "Checking built packages..."
    - ls -l dist/
    - uv run twine check dist/*
    # --- FIX: Use API Token ---
    - echo "Uploading to PyPI..."
    - uv run twine upload --non-interactive -u __token__ -p $PYPI_API_TOKEN dist/*
    # Display release notes
    - echo "Release Notes:"
    - cat release_notes.md
  artifacts:
    paths:
      - release_notes.md # Keep release notes for reference
  rules:
    # --- FIX: Updated regex to include beta tags ---
    # Deploy only when a tag like vX.Y.Z or vX.Y.ZbN is pushed
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+(b\d+)?$/

# --- Create GitLab Release Job ---
create_gitlab_release:
  stage: publish
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs: ["publish_to_pypi"] # Depend on the publish job
  script:
    - echo "Creating GitLab Release for $CI_COMMIT_TAG"
    # Read release notes
    - RELEASE_NOTES=$(cat release_notes.md)
  release:
    name: 'Release $CI_COMMIT_TAG'
    description: './release_notes.md' # Use the release notes file
    tag_name: '$CI_COMMIT_TAG'
    ref: '$CI_COMMIT_TAG'
    assets:
      links:
        - name: 'PyPI Package'
          url: 'https://pypi.org/project/keras-geometric/$CI_COMMIT_TAG/'
          link_type: 'package'
  rules:
    # Create release only when a tag like vX.Y.Z or vX.Y.ZbN is pushed
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+(b\d+)?$/
